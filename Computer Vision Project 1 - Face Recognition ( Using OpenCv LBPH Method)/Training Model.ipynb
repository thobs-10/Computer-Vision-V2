{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "722288bd",
   "metadata": {},
   "source": [
    "# Train Face Recognition Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ffdbf3",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b48efde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "# import the face recognition file we just created that has the classifier in it\n",
    "import Face_Recognition as fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df744055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37fb8ce8",
   "metadata": {},
   "source": [
    "#### Give path to the image you want to test the model with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19cbe266",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = cv2.imread(r'dataset\\test_images\\image0000.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "108a6e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[173 173 167]\n",
      "  [176 176 170]\n",
      "  [178 177 173]\n",
      "  ...\n",
      "  [100 123  79]\n",
      "  [ 99 124  80]\n",
      "  [ 95 122  78]]\n",
      "\n",
      " [[173 173 167]\n",
      "  [175 175 169]\n",
      "  [176 175 171]\n",
      "  ...\n",
      "  [100 120  77]\n",
      "  [ 98 121  77]\n",
      "  [ 94 119  75]]\n",
      "\n",
      " [[172 172 166]\n",
      "  [174 174 168]\n",
      "  [173 174 170]\n",
      "  ...\n",
      "  [102 119  76]\n",
      "  [ 99 119  74]\n",
      "  [ 96 116  71]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[104  38  33]\n",
      "  [106  40  35]\n",
      "  [113  45  40]\n",
      "  ...\n",
      "  [129  61  32]\n",
      "  [126  59  32]\n",
      "  [124  57  30]]\n",
      "\n",
      " [[104  39  31]\n",
      "  [104  39  31]\n",
      "  [110  42  37]\n",
      "  ...\n",
      "  [130  62  33]\n",
      "  [128  59  32]\n",
      "  [126  57  30]]\n",
      "\n",
      " [[101  36  28]\n",
      "  [101  36  28]\n",
      "  [107  39  34]\n",
      "  ...\n",
      "  [130  62  33]\n",
      "  [129  60  33]\n",
      "  [126  57  30]]]\n"
     ]
    }
   ],
   "source": [
    "print(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9930471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face Detected:  [[241  52 209 209]]\n"
     ]
    }
   ],
   "source": [
    "# Feed the model with the test img\n",
    "faces_detected, gray_img = fr.face_detection(test_img)\n",
    "print('Face Detected: ', faces_detected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6785f09",
   "metadata": {},
   "source": [
    "#### Train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769defbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_path dataset\\images\\0\\image0000.jpg\n",
      "id:  0\n",
      "img_path dataset\\images\\0\\image0001.jpg\n",
      "id:  0\n",
      "img_path dataset\\images\\0\\image0002.jpg\n",
      "id:  0\n",
      "img_path dataset\\images\\0\\image0003.jpg\n",
      "id:  0\n",
      "img_path dataset\\images\\0\\image0004.jpg\n",
      "id:  0\n",
      "img_path dataset\\images\\0\\image0005.jpg\n",
      "id:  0\n",
      "img_path dataset\\images\\0\\image0006.jpg\n",
      "id:  0\n",
      "img_path dataset\\images\\0\\image0007.jpg\n",
      "id:  0\n",
      "img_path dataset\\images\\0\\image0008.jpg\n",
      "id:  0\n",
      "img_path dataset\\images\\0\\image0009.jpg\n",
      "id:  0\n",
      "img_path dataset\\images\\0\\image0010.jpg\n",
      "id:  0\n",
      "img_path dataset\\images\\0\\image0011.jpg\n",
      "id:  0\n",
      "img_path dataset\\images\\0\\image0012.jpg\n",
      "id:  0\n",
      "img_path dataset\\images\\0\\image0013.jpg\n",
      "id:  0\n",
      "img_path dataset\\images\\0\\image0014.jpg\n",
      "id:  0\n",
      "img_path dataset\\images\\0\\image0015.jpg\n",
      "id:  0\n",
      "img_path dataset\\images\\0\\image0016.jpg\n",
      "id:  0\n"
     ]
    }
   ],
   "source": [
    "faces, faceID = fr.labels_for_training_data(r'dataset\\images')\n",
    "face_recognizer = fr.train_classifier(faces, faceID) # get the classifier and feed it faces with the id so it can correctly recognize\n",
    "face_recognizer.save('trainingData.yml') # save the model to this location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54cc1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#name = {0:'Thobela', 1: \"Bobo\"} # zero is the label, so if there are more people write it as a long dictionary\n",
    "name = {0:'Thobela'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e21d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "for face in faces_detected:\n",
    "    (x, y, w, h) = face\n",
    "    roi_gray = gray_img[y:y+w, x: x+h]  # roi means reason of interest, it should be y+w\n",
    "    label, confidence = face_recognizer.predict(roi_gray) \n",
    "    print('Confidence : ', confidence) # confidence is how confident the model is with the recognition\n",
    "    print('label : ', label)\n",
    "    fr.draw_rect(test_img, face)\n",
    "    predicted_name = name[label]\n",
    "    fr.place_text(test_img, predicted_name, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a53f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_img = cv2.resize(test_img, (1000, 700))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9e3ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"face detection \", resized_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c38b5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7471ebef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30be570b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eb8514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d625bd79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614358e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
